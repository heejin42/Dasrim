{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import íŒ¨í‚¤ì§€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "from keras import models\n",
    "from keras import preprocessing\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê²½ë¡œ ì´ë™\n",
    "os.chdir(r'./\\ICTí•´ì»¤í†¤\\ì±—ë´‡\\ë°ì´í„°')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‚¬ì „ ì •ì˜\n",
    "PAD = \"<PADDING>\"\n",
    "PAD_INDEX = 0\n",
    "OOV = \"<OOV>\"\n",
    "OOV_INDEX = 1\n",
    "user_name='defalutê°’'\n",
    "\n",
    "okt= Okt()\n",
    "talk= True\n",
    "index=0\n",
    "data = {'bot_q':[],'user_a':[]}\n",
    "bot_a = ''\n",
    "bot_s = ''\n",
    "bot_a_list = {'ê³ ì •':['ë‚˜ë¥¼ ìƒì§•í•˜ëŠ” ê²ƒì„ ì €ë ‡ê²Œ í‘œí˜„í•˜ì‹  ì´ìœ ê°€ ë¬´ì—‡ì¸ê°€ìš”?\\n',\n",
    "                    'ì™œ ê·¸ëŸ° ìƒê°ì´ ë“œì…¨ëŠ”ì§€ ì„¤ëª…í•´ ì£¼ì‹¤ ìˆ˜ ìˆë‚˜ìš”?\\n',\n",
    "                    f'ìµœê·¼ì— {user_name}ë‹˜ì´ ë³¸ì¸ì„ ê·¸ë ‡ê²Œ ëŠë‚„ë§Œí•œ ì¼ë“¤ì´ ìˆì—ˆë‚˜ìš”?\\n',\n",
    "                    'ê·¸ëŸ° ìƒí™©ì—ì„œ ìŠ¤ì³ì§€ë‚˜ê°„ ìƒê°ì´ ìˆìœ¼ì‹ ê°€ìš”?\\n',\n",
    "                    'ì£¼ë³€ ì‚¬ëŒì´ ì´ëŸ° ìƒê°ì„ ê°€ì§€ê³  ìˆë‹¤ë©´ ë­ë¼ê³  ë§ì„ í•´ì£¼ê² ì–´ìš”?\\n',\n",
    "                    'ê·¸ë ‡ì§€ë§Œ ë³¸ì¸ì— ëŒ€í•´ ì§€ê¸ˆê¹Œì§€ ì•Œì•„ê°€ëŠ” ì‹œê°„ì´ ë¶€ì¡±í–ˆë˜ê±° ê°™ì•„ìš” ì–´ë–»ê²Œ ìƒê°í•˜ì‹œë‚˜ìš”?\\n',\n",
    "                    'ê·¸ë˜ë„ ì˜¤ëŠ˜ ì´ë ‡ê²Œ ì´ì•¼ê¸°ë¥¼ ë‚˜ëˆ„ë©´ì„œ ê¸°ë¶„ì´ ì¢€ í’€ë¦¬ì…¨ë‚˜ìš”?, ì•ìœ¼ë¡œë„ ì œê°€ ë„ì™€ë“œë¦´ê»˜ìš” í•¨ê»˜í•´ìš”!'],\n",
    "              'ì‹œì‘':['ì•ˆë…•í•˜ì„¸ìš” ì—˜ë¦¬ğŸ˜ì—ìš”! ì €ì™€ í•¨ê»˜ ì–˜ê¸°ë¥¼ ë‚˜ëˆ„ì–´ ë´ìš”!','í˜¹ì‹œë¼ë„ ì¤‘ê°„ì— ë©ˆì¶”ê³  ì‹¶ìœ¼ì‹œë©´ ëë‚´ê¸°ë¼ê³  ì…ë ¥í•´ì£¼ì„¸ìš”!'],\n",
    "         'ì•ˆë˜ë‹¤':'ë§ì´ ì •ì‹  ì—†ìœ¼ì…¨ë‚˜ë´ìš” ğŸ˜¥',\n",
    "         'ê³µê°':f'ë§ì•„ìš” ì œ ìƒê°ë„ ê·¸ë˜ìš”. {user_name}ë‹˜ì€ ì¶©ë¶„íˆ ë…¸ë ¥í•˜ì…¨ì–´ìš”.',\n",
    "             'ì¢…ë£Œ':'\\nì¢…ë£Œí•©ë‹ˆë‹¤',\n",
    "             'ë§ˆë¬´ë¦¬':'ê·¸ë˜ë„ ì˜¤ëŠ˜ ì´ë ‡ê²Œ ì´ì•¼ê¸°ë¥¼ ë‚˜ëˆ„ë©´ì„œ ê¸°ë¶„ì´ ì¢€ í’€ë¦¬ì…¨ë‚˜ìš”? \\nì•ìœ¼ë¡œë„ ì œê°€ ë„ì™€ë“œë¦´ê»˜ìš” í•¨ê»˜í•´ìš”!'}\n",
    "bot_a_emotion={'í–‰ë³µ':'ì™€ ë„ˆë¬´ í–‰ë³µí•˜ì…¨ê² ì–´ìš”!! ê¸°ì¨ì€ ë‚˜ëˆ„ë©´ ë°°ê°€ ëœë°ìš”!! ì œê°€ ì œê³±ìœ¼ë¡œ ëŠ˜ë ¤ë“œë¦´ê»˜ìš”!!!',\n",
    "              'ë¶„ë…¸':'ëŒ€ë”°ëŒ€ë”° í™”ë‚˜ì…¨ê² ë‹¤.. ì–´ë–»ê²Œ ì°¸ìœ¼ì…¨ì–´ìš” ëŒ€ë‹¨í•´ìš”!ğŸ‘',\n",
    "              'ì¤‘ë¦½':'ì•„.. ê·¸ëŸ¬ì…¨êµ¬ë‚˜ ì¶©ë¶„íˆ ê·¸ëŸ´ ìˆ˜ ìˆì£ !',\n",
    "              'ìŠ¬í””':'ë§ˆìŒì•„í”„ì‹œê² ì–´ìš” ..ğŸ˜¢ ìŠ¬í””ì€ ë‚˜ëˆ„ë©´ ë‚˜ëˆ ì§„ë‹¤ê³  í–ˆì–´ìš”..!'}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í˜•íƒœì†Œë¶„ì„ í•¨ìˆ˜\n",
    "def pos_tag(sentences):\n",
    "    \n",
    "    # KoNLPy í˜•íƒœì†Œë¶„ì„ê¸° ì„¤ì •\n",
    "    tagger = Okt()\n",
    "    \n",
    "    # ë¬¸ì¥ í’ˆì‚¬ ë³€ìˆ˜ ì´ˆê¸°í™”\n",
    "    sentences_pos = []\n",
    "    \n",
    "    # ì¸í’‹ì´ ë¦¬ìŠ¤íŠ¸ë©´\n",
    "    if isinstance(sentences,list):\n",
    "    # ëª¨ë“  ë¬¸ì¥ ë°˜ë³µ\n",
    "        for sentence in sentences:\n",
    "            # [\\\"':;~()] íŠ¹ìˆ˜ê¸°í˜¸ ì œê±°\n",
    "            sentence = re.sub(\"[ã„±-ã…ã…-ã…£-=+,#/\\?:^$.@*\\\"â€»~&%ã†!ã€\\\\â€˜|\\(\\)\\[\\]\\<\\>`\\'â€¦ã€‹]\", \" \", sentence)\n",
    "            \n",
    "            \n",
    "            # ë°°ì—´ì¸ í˜•íƒœì†Œë¶„ì„ì˜ ì¶œë ¥ì„ ë„ì–´ì“°ê¸°ë¡œ êµ¬ë¶„í•˜ì—¬ ë¶™ì„\n",
    "            sentence = \" \".join(tagger.morphs(sentence))\n",
    "            sentences_pos.append(sentence)\n",
    "            \n",
    "    # strì´ë©´        \n",
    "    elif isinstance(sentences, str):\n",
    "        sentences=re.sub(\"[ã„±-ã…ã…-ã…£-=+,#/\\?:^$.@*\\\"â€»~&%ã†!ã€\\\\â€˜|\\(\\)\\[\\]\\<\\>`\\'â€¦ã€‹]\", \" \", sentences)\n",
    "        sentences_pos= \" \".join(tagger.morphs(sentences))\n",
    "        \n",
    "    return sentences_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_text_to_index_for_classification(sentences, vocabulary): \n",
    "    sentences_index = []\n",
    "    if isinstance(sentences,list):\n",
    "        # ëª¨ë“  ë¬¸ì¥ì— ëŒ€í•´ì„œ ë°˜ë³µ\n",
    "        for sentence in sentences:\n",
    "            sentence_index = []\n",
    "\n",
    "            # ë¬¸ì¥ì˜ ë‹¨ì–´ë“¤ì„ ë„ì–´ì“°ê¸°ë¡œ ë¶„ë¦¬\n",
    "            for word in sentence.split():\n",
    "                if vocabulary.get(word) is not None:\n",
    "                    # ì‚¬ì „ì— ìˆëŠ” ë‹¨ì–´ë©´ í•´ë‹¹ ì¸ë±ìŠ¤ë¥¼ ì¶”ê°€\n",
    "                    sentence_index.extend([vocabulary[word]])\n",
    "                else:\n",
    "                    # ì‚¬ì „ì— ì—†ëŠ” ë‹¨ì–´ë©´ OOV ì¸ë±ìŠ¤ë¥¼ ì¶”ê°€\n",
    "                    sentence_index.extend([vocabulary[OOV]])\n",
    "\n",
    "            if len(sentence_index) > max_sequences:\n",
    "                sentence_index = sentence_index[:max_sequences]\n",
    "\n",
    "            # ìµœëŒ€ ê¸¸ì´ì— ì—†ëŠ” ê³µê°„ì€ íŒ¨ë”© ì¸ë±ìŠ¤ë¡œ ì±„ì›€\n",
    "            sentence_index += (max_sequences - len(sentence_index)) * [vocabulary[PAD]]\n",
    "\n",
    "            # ë¬¸ì¥ì˜ ì¸ë±ìŠ¤ ë°°ì—´ì„ ì¶”ê°€\n",
    "            sentences_index.append(sentence_index)\n",
    "    elif isinstance(sentences, str):\n",
    "        sentence_index = []\n",
    "        for word in sentences.split():\n",
    "            if vocabulary.get(word) is not None:\n",
    "                # ì‚¬ì „ì— ìˆëŠ” ë‹¨ì–´ë©´ í•´ë‹¹ ì¸ë±ìŠ¤ë¥¼ ì¶”ê°€\n",
    "                sentence_index.extend([vocabulary[word]])\n",
    "            else:\n",
    "                # ì‚¬ì „ì— ì—†ëŠ” ë‹¨ì–´ë©´ OOV ì¸ë±ìŠ¤ë¥¼ ì¶”ê°€\n",
    "                sentence_index.extend([vocabulary[OOV]])\n",
    "\n",
    "        if len(sentence_index) > max_sequences:\n",
    "            sentence_index = sentence_index[:max_sequences]\n",
    "\n",
    "        # ìµœëŒ€ ê¸¸ì´ì— ì—†ëŠ” ê³µê°„ì€ íŒ¨ë”© ì¸ë±ìŠ¤ë¡œ ì±„ì›€\n",
    "        sentence_index += (max_sequences - len(sentence_index)) * [vocabulary[PAD]]\n",
    "\n",
    "        sentences_index.append(sentence_index)\n",
    "    return sentences_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Sentence Emotion\n",
      "0  ì„œí•´ ìˆ˜ìì›ë„ í•œë¥˜ë¼ì„œ ê·¸ë™ì•ˆ ë¶ˆë²•ì¡°ì—… ë°©ì¹˜í–ˆë‚˜?      ë¶„ë…¸\n",
      "1                     ë‹ˆê°€ ì¸ê°„ì´ê°€.      ë¶„ë…¸\n",
      "2    ê°•ì•„ì§€ë¥¼ ë•Œë¦¬ê³  ìœ ê¸°í•˜ëŠ”ê²ƒë§Œ í•™ëŒ€ëŠ” ì•„ë‹™ë‹ˆë‹¤!      ë¶„ë…¸\n",
      "3        í•˜ì—¬ê°„ ìš°ë¦¬ë‚˜ë¼ êµìœ¡ì—” ë¯¸ë˜ê°€ ì—†ì–´!!      ë¶„ë…¸\n",
      "4     ì±„ë„ì—ì´ êµ°ë¶€ ê°œì¸ê±° ì¸ì¦í•˜ëƒ ë™ì•„ì¼ë³´ì•¼!!      ë¶„ë…¸\n"
     ]
    }
   ],
   "source": [
    "# íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "df_main = pd.read_csv('sentences.csv',encoding='utf-8')\n",
    "print(df_main.head())\n",
    "a=df_main['Emotion'].unique()\n",
    "category =list(a)\n",
    "CATEGORY = len(category)\n",
    "\n",
    "# ë¶„ë…¸ 0,ìŠ¬í”” 1, ì¤‘ë¦½ 2, í–‰ë³µ 3,\n",
    "# ì¹´í…Œê³ ë¦¬ ì¸ë±ìŠ¤\n",
    "\n",
    "category_to_index = {word: index for index, word in enumerate(category)}\n",
    "\n",
    "index_to_category = {index: word for index, word in enumerate(category)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "ori_sentence =[]\n",
    "# ë°ì´í„° í”„ë ˆì„ listí™”\n",
    "for i in range(len(df_main)):\n",
    "    tmp =[]\n",
    "    tmp.append(str(i+1))\n",
    "    tmp.append(df_main.iloc[i].Sentence)\n",
    "    tmp.append(df_main.iloc[i].Emotion)\n",
    "    ori_sentence.append(tmp)\n",
    "    \n",
    "# ë¬¸ì¥ í˜•íƒœì†Œ ë¶„ì„ ë° ì „ì²˜ë¦¬\n",
    "sente=[]\n",
    "for i in ori_sentence:\n",
    "    sente.append(i[1])\n",
    "\n",
    "senten = pos_tag(sente)\n",
    "\n",
    "# ë‹¨ì–´ë“¤ì˜ ë°°ì—´ ìƒì„±\n",
    "for sentence in senten:\n",
    "    for word in sentence.split():\n",
    "        words.append(word)\n",
    "\n",
    "# ê¸¸ì´ê°€ 0ì¸ ë‹¨ì–´ëŠ” ì‚­ì œ\n",
    "words = [word for word in words if len(word) > 0]\n",
    "\n",
    "# ì¤‘ë³µëœ ë‹¨ì–´ ì‚­ì œ\n",
    "words = list(set(words))\n",
    "\n",
    "# ì œì¼ ì•ì— íƒœê·¸ ë‹¨ì–´ ì‚½ì…\n",
    "words[:0] = [PAD, OOV]\n",
    "\n",
    "VOCAB_SIZE = len(words)\n",
    "# print(VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë¬¸ì¥ ê¸¸ì´ í™•ì¸\n",
    "max_length = max(len(l) for l in senten)\n",
    "avg_length = sum(map(len, senten))/len(senten)\n",
    "# print('ë¦¬ë·°ì˜ ìµœëŒ€ ê¸¸ì´ : {}'.format(max_length))\n",
    "# print('ë¦¬ë·°ì˜ í‰ê·  ê¸¸ì´ : {}'.format(avg_length))\n",
    "max_sequences= int(avg_length) + 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë‹¨ì–´ì™€ ì¸ë±ìŠ¤ì˜ ë”•ì…”ë„ˆë¦¬ ìƒì„±\n",
    "word_to_index = {word: index for index, word in enumerate(words)}\n",
    "index_to_word = {index: word for index, word in enumerate(words)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "load_c_model = models.load_model('main_lstm_cl.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_emotion(text):\n",
    "    pre_text = pos_tag(text)\n",
    "    pre_x=convert_text_to_index_for_classification(pre_text, word_to_index)\n",
    "    result=np.argmax(load_c_model.predict(np.asarray(pre_x).reshape(1,max_sequences)))\n",
    "    return index_to_category[result]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chatbot_elly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_Q(user_a, idx):\n",
    "    print('\\n - - - - - - \\n')\n",
    "    # ì±—ë´‡ ì§ˆë¬¸\n",
    "    bot_a=bot_a_list['ê³ ì •'][idx]\n",
    "\n",
    "    # ëŒ€í™” ë‚´ìš© ì €ì¥\n",
    "    data['bot_q'].append(bot_a)\n",
    "    data['user_a'].append(user_a)\n",
    "\n",
    "    if idx == 2:\n",
    "        # ìœ ì € ëŒ€ë‹µ ê°ì • ë¶„ì„ í›„ ë§ëŠ” ì§ˆë¬¸ ì €ì¥\n",
    "        user_emotion = predict_emotion(user_a)\n",
    "        bot_react=bot_a_emotion[user_emotion]\n",
    "    elif idx == 4:\n",
    "        bot_react=bot_a_list['ê³µê°']\n",
    "    else :\n",
    "        bot_react=''\n",
    "            \n",
    "        \n",
    "    return bot_a, bot_react\n",
    "    # ìœ ì € ì§ˆë¬¸ ë³€ìˆ˜ ì´ˆê¸°í™” ì§ˆë¬¸ ì¸ë±ìŠ¤ ê°’ ì¦ê°€ ë° 3ì´ˆ ì§€ì—°\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì•ˆë…•í•˜ì„¸ìš” ì—˜ë¦¬ğŸ˜ì—ìš”! ì €ì™€ í•¨ê»˜ ì–˜ê¸°ë¥¼ ë‚˜ëˆ„ì–´ ë´ìš”!\n",
      "í˜¹ì‹œë¼ë„ ì¤‘ê°„ì— ë©ˆì¶”ê³  ì‹¶ìœ¼ì‹œë©´ ëë‚´ê¸°ë¼ê³  ì…ë ¥í•´ì£¼ì„¸ìš”!\n",
      "- - - -\n",
      "ë‚˜ë¥¼ ìƒì§•í•˜ëŠ” ê²ƒì„ ì €ë ‡ê²Œ í‘œí˜„í•˜ì‹  ì´ìœ ê°€ ë¬´ì—‡ì¸ê°€ìš”?\n",
      "\n",
      "í™œí™”ì‚°ì²˜ëŸ¼ ë¶ˆì´ ë¶™ì—ˆì—ˆì§€ë§Œ ì§€ê¸ˆì€ ê·¸ë ‡ì§€ ì•Šê³  êº¼ì ¸ë²„ë¦° ê²ƒ ê°™ë‹¤.\n",
      "\n",
      " - - - - - - \n",
      "\n",
      "ì™œ ê·¸ëŸ° ìƒê°ì´ ë“œì…¨ëŠ”ì§€ ì„¤ëª…í•´ ì£¼ì‹¤ ìˆ˜ ìˆë‚˜ìš”?\n",
      "\n",
      "ì§€ê¸ˆì€ ë­”ê°€ ì°¨ê°€ì›Œì¡Œê³  ì‰¬ì–´ì•¼ í•  ê²ƒ ê°™ì€ ê¸°ë¶„ì´ë¼ ê·¸ë¬ìŠµë‹ˆë‹¤.\n",
      "\n",
      " - - - - - - \n",
      "\n",
      "ì•„.. ê·¸ëŸ¬ì…¨êµ¬ë‚˜ ì¶©ë¶„íˆ ê·¸ëŸ´ ìˆ˜ ìˆì£ !\n",
      "ìµœê·¼ì— defalutê°’ë‹˜ì´ ë³¸ì¸ì„ ê·¸ë ‡ê²Œ ëŠë‚„ë§Œí•œ ì¼ë“¤ì´ ìˆì—ˆë‚˜ìš”?\n",
      "\n",
      "ë‚ ì”¨ê°€ ì¶”ì›Œì ¸ì„œ ìˆ˜ì¡±ëƒ‰ì¦ì´ ì‹¬í•´ì ¸ì„œ ëª¸ ì»¨ë””ì…˜ì´ ì•ˆì¢‹ì•„ ì¡Œì–´ìš”. \n",
      "\n",
      " - - - - - - \n",
      "\n",
      "ê·¸ëŸ° ìƒí™©ì—ì„œ ìŠ¤ì³ì§€ë‚˜ê°„ ìƒê°ì´ ìˆìœ¼ì‹ ê°€ìš”?\n",
      "\n",
      "ë”°ëœ»í•œ ê³³ì— ê°€ì„œ ì‰¬ê³ ì‹¶ë‹¤.\n",
      "\n",
      " - - - - - - \n",
      "\n",
      "ë§ì•„ìš” ì œ ìƒê°ë„ ê·¸ë˜ìš”. defalutê°’ë‹˜ì€ ì¶©ë¶„íˆ ë…¸ë ¥í•˜ì…¨ì–´ìš”.\n",
      "ì£¼ë³€ ì‚¬ëŒì´ ì´ëŸ° ìƒê°ì„ ê°€ì§€ê³  ìˆë‹¤ë©´ ë­ë¼ê³  ë§ì„ í•´ì£¼ê² ì–´ìš”?\n",
      "\n",
      "ì–´ì„œ ë“¤ì–´ê°€ ì‰¬ì–´.. ì‰¬ë©´ì„œ í•´ì•¼ì§€..\n",
      "\n",
      " - - - - - - \n",
      "\n",
      "ê·¸ë ‡ì§€ë§Œ ë³¸ì¸ì— ëŒ€í•´ ì§€ê¸ˆê¹Œì§€ ì•Œì•„ê°€ëŠ” ì‹œê°„ì´ ë¶€ì¡±í–ˆë˜ê±° ê°™ì•„ìš” ì–´ë–»ê²Œ ìƒê°í•˜ì‹œë‚˜ìš”?\n",
      "\n",
      "ë§ì•„ìš”...\n",
      "\n",
      " - - - - - - \n",
      "\n",
      "ê·¸ë˜ë„ ì˜¤ëŠ˜ ì´ë ‡ê²Œ ì´ì•¼ê¸°ë¥¼ ë‚˜ëˆ„ë©´ì„œ ê¸°ë¶„ì´ ì¢€ í’€ë¦¬ì…¨ë‚˜ìš”?, ì•ìœ¼ë¡œë„ ì œê°€ ë„ì™€ë“œë¦´ê»˜ìš” í•¨ê»˜í•´ìš”!\n",
      "ë„¤ ê³ ë§ˆì›Œìš”\n",
      "ê·¸ë˜ë„ ì˜¤ëŠ˜ ì´ë ‡ê²Œ ì´ì•¼ê¸°ë¥¼ ë‚˜ëˆ„ë©´ì„œ ê¸°ë¶„ì´ ì¢€ í’€ë¦¬ì…¨ë‚˜ìš”? \n",
      "ì•ìœ¼ë¡œë„ ì œê°€ ë„ì™€ë“œë¦´ê»˜ìš” í•¨ê»˜í•´ìš”!\n"
     ]
    }
   ],
   "source": [
    "# ëë‚´ê¸° ì „ê¹Œì§€ ë°˜ë³µ\n",
    "for i in range(len(bot_a_list['ê³ ì •'])+1):\n",
    "    if i==0:\n",
    "        # ì´ˆë°˜ ë©˜íŠ¸\n",
    "        for ment in bot_a_list['ì‹œì‘']:\n",
    "            print(ment)\n",
    "            \n",
    "        print('- - - -')\n",
    "        print(bot_a_list['ê³ ì •'][0])\n",
    "        continue\n",
    "    user=input()\n",
    "    # ìœ ì €ê°€ ì›í•˜ë©´ ì¢…ë£Œ\n",
    "    if user == 'ëë‚´ê¸°':\n",
    "        print(bot_a_list['ì¢…ë£Œ'])\n",
    "        break\n",
    "    elif i < len(bot_a_list['ê³ ì •']):\n",
    "        bot_q, bot_re=generate_Q(user,i)\n",
    "        if bot_re != '':\n",
    "            print(bot_re)\n",
    "        print(bot_q)\n",
    "    else :\n",
    "        print(bot_a_list['ë§ˆë¬´ë¦¬'])\n",
    "    time.sleep(3)\n",
    "    \n",
    "# data.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
